<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <!-- <meta name="description"
    content="We introduce LargeSceneModel, which utilizes two unposed and uncalibrated images as input, and reconstructs the explicit radiance field, encompassing geometry, appearance, and semantics in real-time.">
  <meta property="og:title" content="Large Scene Model: Real-time Unposed Images to Semantic 3D" />
  <meta property="og:description" content="Novel view synthesis via feed-forward 3D Gaussian inference from two images." /> -->
  <!-- <meta property="og:url" content="https://pixelsplat.github.io/" />
  <meta property="og:image" content="https://pixelsplat.github.io/static/images/banner.png" /> -->
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />

  <!-- <meta name="twitter:title" content="Large Scene Model: Real-time Unposed Images to Semantic 3D"> -->
  <!-- <meta name="twitter:description" content="Novel view synthesis via feed-forward 3D Gaussian inference from two images."> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="https://pixelsplat.github.io/static/images/banner.png"> -->
  <!-- <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <!-- <meta name="keywords" content="NeRF, novel view synthesis, 3D Gaussians"> -->
  <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->

  <title>CrashLLM</title>



  
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">

  <link rel="stylesheet" href="static/css/bootstrap.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <!-- <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script> -->
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bootstrap.bundle.min.js"></script>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
  <link rel="stylesheet" href="assets/css/bog/app.css">

  <link rel="stylesheet" href="assets/css/bog/bootstrap.min.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
      </script>

  <link rel="stylesheet" href="assets/css/bog/dics.min.css">
  <script src="assets/js/bog/dics.min.js"></script>
  <script src="assets/js/bog/video_comparison.js"></script>
  <script>
      document.addEventListener('DOMContentLoaded', domReady);
      function domReady() {
          for (const e of document.querySelectorAll(".b-dics")) {
              new Dics({
                  container: e,
                  textPosition: "top"
              });
          }
      }
  </script>
</head>

<style>
  .before,
  .after {
    margin: 0;
  }

  .summary-box {
  background-color: #B8CFEA; /* Light blue background */
  /* border-left: 5px solid #2b8af7; Dark blue left border */
  padding: 20px;
  margin: 10px 0;
  font-family: Arial, sans-serif;
  border-radius: 5px; /* Rounds the corners */
  border: 2px solid #91A0C9; /* Fine orange border */
  }

  p {
      margin: 0;
      color: #333; /* Dark text for better readability */
  }
  .before figcaption,
  .after figcaption {
    background: #fff;
    border: 1px solid #c0c0c0;
    border-radius: 4px;
    color: #2e3452;
    opacity: 0.8;
    padding: 4px;
    position: absolute;
    top: 50%;
    transform: translateY(-50%);
    line-height: 70%;
  }

  .before figcaption {
    left: 4px;
  }

  .after figcaption {
    right: 4px;
  }
</style>


<body>

  <div class="container">
    <!-- Title --> 
    <!-- <h1 class="pt-5 title is-3" style="font-size: 34px;">Learn Traffic <span style="color: #D80725 ;font-weight: bolder;"></span>Crash</span> as Language —— <br> Datasets, Benchmarks and What-if Causal Analysis</h1> -->
      <h1 class="pt-5 title">Learn Traffic <span style="color: #D80725;font-weight: bolder;">Crash</span> as <span style="color: #77aae5;font-weight: bolder;">Language</span> —— Datasets, Benchmarks and What-if Causal Analysis</h1>

    <!-- <div class="d-flex flex-row justify-content-center">
      <a>Anonymous Authors</a>
    </div> -->

    
    <div class="w-100 d-flex flex-row justify-content-center mt-4 gap-2">
      <!-- Paper PDF -->
      <a href="https://crashllm.github.io/" target="_blank" class="btn btn-dark" role="button">
        <span class="icon">
          <i class="ai ai-arxiv"></i>
        </span>
        <span>Paper</span>
      </a>

      <!-- Code -->
      <!-- <a href="https://github.com/dcharatan/pixelsplat" target="_blank" class="btn btn-dark" role="button">
        <span class="icon">
          <i class="fab fa-github"></i>
        </span>
        <span>Code</span>
      </a> -->

      <!-- Video -->
      <a href="https://crashllm.github.io/" target="_blank" class="btn btn-dark" role="button">
        <span class="icon">
          <i class="fab fa-youtube"></i>
        </span>
        <span>Video</span>
      </a>  

      <!-- Pre-trained Models -->
      <!-- <a href="https://drive.google.com/drive/folders/18nGNWIn8RN0aEWLR6MC2mshAkx2uN6fL?usp=sharing" target="_blank" class="btn btn-dark" role="button">
        <span class="icon">
          <i class="fas fa-database"></i>
        </span>
        <span>Pre-trained Models</span>
      </a> -->

      <!-- Sample Data -->
      <a href="https://crashllm.github.io/" target="_blank" class="btn btn-dark" role="button">
        <span class="icon">
          <i class="fas fa-database"></i>
        </span>
        <span>Dataset</span>
      </a>
    </div>




    <!-- Teaser -->
    <div class="w-100 my-4">
      <img src="static/images/fig1.png" class="img-fluid w-100 mt-2 mb-3" alt="comparison on ACID dataset" />
      <div class="summary-box tldr mb-4">
        <strong>Overview of <u>CrashLLM</u></strong>: Traffic crashes present a significant problem worldwide. We collected traffic crash records from Washington state and utilized textualization to reformulate these records. The tuned LLMs take this input, predict and analyze traffic crashes.
      </div>
    </div>



    <!-- </section> -->
    <div class="columns is-centered has-text-centered">
    <!-- Abstract -->
    <h2 class="title is-3 has-text-centered"><span style="color: #2c6fbc ;font-weight: bolder;">Abstract</span></h2>
    <!-- <span style="background: linear-gradient(to right, #91A0C9, #4A69BD); -webkit-background-clip: text; color: transparent; font-weight: bolder;">Abstract</span> -->
    <div class="content has-text-justified">
      <p>
      </div><p class="mb-4">
        The increasing rate of road accidents worldwide results not only in significant loss of life but also imposes severe financial burdens on societies. Current research in traffic accident analysis has predominantly approached the problem as classification tasks, focusing mainly on learning-based classification or ensemble learning methods. These approaches often overlook the intricate relationships among the complex human and contextual factors related to traffic crashes and risky situations. In contrast, we initially formulate a large-scale traffic accident dataset consisting of abundant textual and visual information. We then present a novel application of large language models (LLMs) to enhance causal understanding and improve forecasting of traffic crash specifics, such as accident types and injury severity. Utilizing this rich dataset, we calibrate and fine-tune various LLM configurations to predict detailed accident outcomes based on contextual and environmental inputs. Our AccidentLLM diverges from traditional ensemble machine learning models by leveraging the inherent capabilities of LLMs to parse and learn from complex, unstructured data, thereby enabling a more nuanced analysis of contributing factors. Preliminary results indicate that our LLM-based approach not only predicts the severity of accidents but also classifies different types of accidents and predicts injury outcomes, all with an accuracy above 92%. We make our benchmark, datasets, and model public available for further exploration.
        </p>
        
    

    <!-- Method -->
    <br>
    <h2 class="title is-3 has-text-centered"><span style="color: #2c6fbc ;font-weight: bolder;">Summary of Prompt Design</span></h2>
    
    <div class="content has-text-justified">
      <img src="static/images/fig2.jpg" class="img-fluid w-100 mt-2 mb-3" alt="comparison on ACID dataset" />
      <!-- <p>
        Our method utilizes input images from which pixel-aligned point maps are regressed using a generic Transformer. Point-based scene parameters are then predicted employing another Transformer that facilitates local context aggregation and hierarchical fusion. The model elevate 2D pre-trained feature to facilate consistent 3D feature field. It is supervised end-to-end, minimizing the loss function through comparisons against ground truth and rasterized feature maps on new views. During the inference stage, our approach is capable of predicting the scene representation without requiring camera parameters, enabling real-time semantic 3D reconstruction.<br> <br>
      </p> -->
      </div>


    
    <!-- Comparisons -->
    <!-- <h2 class="title is-3 has-text-centered"><span style="color: #f06d15 ;font-weight: bolder;">Results</span></h2> -->
    <!-- <br>
    <div class="content has-text-justified"> -->
      <!-- <p>
        Our method utilizes input images from which pixel-aligned point maps are regressed using a generic Transformer. Point-based scene parameters are then predicted employing another Transformer that facilitates local context aggregation and hierarchical fusion. The model elevate 2D pre-trained feature to facilate consistent 3D feature field. It is supervised end-to-end, minimizing the loss function through comparisons against ground truth and rasterized feature maps on new views. During the inference stage, our approach is capable of predicting the scene representation without requiring camera parameters, enabling real-time semantic 3D reconstruction.<br> <br>
      </p> -->
      <!-- </div> -->

    <!-- <div class="columns is-centered">
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <video id="matting-video" autoplay controls muted playsinline width="19%">
              <source src="static/videos/689.mp4"
              type="video/mp4">
            </video>
            <video id="matting-video" autoplay controls muted playsinline width="19%">
              <source src="static/videos/705.mp4"
              type="video/mp4">
            </video>
            <video id="matting-video" autoplay controls muted playsinline width="19%">
              <source src="static/videos/714.mp4"
              type="video/mp4">
            </video>
            <video id="matting-video" autoplay controls muted playsinline width="19%">
              <source src="static/videos/754.mp4"
              type="video/mp4">
            </video>
            <video id="matting-video" autoplay controls muted playsinline width="19%">
              <source src="static/videos/755.mp4"
              type="video/mp4">
            </video>
          </div>
        </div>
      </div> -->

      <!-- <div class="column">
        <br>
        <div class="columns is-centered">
          <div class="column content">
            <video id="matting-video" autoplay controls muted playsinline width="19%">
              <source src="static/videos/761.mp4"
              type="video/mp4">
            </video>
            <video id="matting-video" autoplay controls muted playsinline width="19%">
              <source src="static/videos/766.mp4"
              type="video/mp4">
            </video>
            <video id="matting-video" autoplay controls muted playsinline width="19%">
              <source src="static/videos/781.mp4"
              type="video/mp4">
            </video>
            <video id="matting-video" autoplay controls muted playsinline width="19%">
              <source src="static/videos/791.mp4"
              type="video/mp4">
            </video>
            <video id="matting-video" autoplay controls muted playsinline width="19%">
              <source src="static/videos/797.mp4"
              type="video/mp4">
            </video>
          </div>
        </div>
      </div> -->


    <!-- Footer -->
    <footer class="border-top mt-5 py-4">
      <!-- This page's code uses elements from this <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
        target="_blank">Academic Project Page
        Template</a>.
    </footer>
  </div> -->
</body>

</html>